# 시선AI Coder 프로젝트 - 투입 인력 및 로드맵

**작성일**: 2026년 1월 26일
**서브PO**: 주용수
**버전**: 2.0 (현실 제약 반영)

> **구현 문서 2/5** | 이전: [로드맵](./roadmap_ko.md) | 다음: [비용 분석](./cost_analysis_ko.md) | [폴더 인덱스](./README.md)

---

## 1. 프로젝트 개요

### 1.1 조직 구조 및 역할 분담

```
프로젝트 총괄 (PO): 문기봉 상무 (대보DX)
    │
    ├─ PoC/구현 파트: 대보DX
    │   └ 담당: 문기봉 상무 (단독)
    │   └ 역할: 프로토타입 개발, 기능 구현, 데모 시연
    │   └ 기간: ~3월 (PoC 완료까지)
    │
    └─ R&D/상용화 파트: 시선AI
        └ 서브PO: 주용수
        └ Phase 1 (1-3월): 서포트 역할 (인프라 + vLLM 배포 지원)
        └ Phase 2 (4월~): 본격 개발 투입
```

### 1.2 현실 제약조건 (2026년 1월 기준)

| 제약               | 내용                        |
| ---------------- | ------------------------- |
| **대보DX**         | 문기봉 상무가 3월까지 PoC 개발 단독 진행 |
| **시선AI**         | 3월까지 실질적 인력 투입 어려움        |
| **시선AI 3월까지 역할** | 서포트 관점 지원 (인프라 + vLLM 배포) |
| **모델 목표**        | 3월 말까지 가장 간단한 모델로 PoC 테스트 |

### 1.3 목표

- **Phase 1 (3월)**: 대보DX PoC 성공 지원 (SoftBase xFrame5 데모)
- **Phase 2 (6월~)**: 시선AI 본격 개발 → 상용화 준비

### 1.4 GPU 인프라

- 대보DX(문기봉 상무)와 GPU 인프라 공유 예정

---

## 2. 개발 항목 및 범위

### 2.1 Phase 1 (1-3월): 역할 분담

> **핵심**: 대보DX가 PoC 개발 주도, 시선AI는 서포트

#### 대보DX 담당 (문기봉 상무 단독)

| 항목 | 범위 | 산출물 |
|------|------|--------|
| **프로토타입 개발** | Coder PoC 완성 | 동작하는 데모 |
| **CLI 명령어 구현** | generate, batch, models | CLI 도구 |
| **파일 편집 기능** | 6단계 파이프라인 + Diff | 편집 기능 |
| **Eclipse 플러그인** | UI 통합 | 플러그인 |
| **SoftBase 데모** | xFrame5 코드 생성 시연 | 데모 성공 |

#### 시선AI 담당 (서포트)

| 항목                 | 범위                                | 입력 → 출력             | 담당               |
| ------------------ | --------------------------------- | ------------------- | ---------------- |
| **S1. GPU 인프라 셋업** | 대보DX GPU 서버 환경 구성                 | 서버 + 요구사항 → 환경 구성   | MLOps (파트타임)     |
| **S2. vLLM 배포 지원** | vLLM >= 0.6, tool calling         | 모델 + GPU → 추론 엔드포인트 | MLOps (파트타임)     |
| **S3. 간단한 모델 준비**  | 기존 모델 활용 (GPT-OSS 20B 또는 Qwen32B) | 기존 모델 → PoC 테스트용    | ML (최소 투입)       |
| **S4. 기술 자문**      | 아키텍처, 모델, API 관련 질의응답             | 질문 → 가이드            | Tech Lead (파트타임) |

**모델 전략 (현실적)**:
- **옵션 A**: GPT-OSS 20B 그대로 사용 (이미 94% 품질, 권장)
- **옵션 B**: Qwen32B-AWQ + 프롬프트 조정 (54% → 목표 70%+)
- **결정 시점**: 2월 중순 (GPU 환경 구성 후)

### 2.2 Phase 2 (4-6월): 시선AI 본격 투입

#### A. 모델/ML 영역

| 항목 | 범위 | 입력 → 출력 | 우선순위 |
|------|------|------------|---------|
| **A1. 모델 품질 개선** | Qwen32B(54%) → 80%+ 달성 | 베이스 모델 + xFrame5 데이터 → 개선 모델 | P0 (6월) |
| **A2. 경량 모델 최적화** | 7B 모델로 QA 전용 85%+ 품질 | 7B 모델 + QA 데이터 → QA 전용 모델 | P1 (6월) |
| **A3. 멀티 모델 라우팅** | 작업별 자동 모델 선택 | 작업 요청 → 최적 모델 선택 + 응답 | P1 (6월) |
| **A4. Template 통합** | 모델별 다른 Template 문제 해결 | 다양한 모델 → 범용 Template | P1 (6월) |

#### B. 인프라/배포 영역

| 항목 | 범위 | 입력 → 출력 | 우선순위 |
|------|------|------------|---------|
| **B1. 동시 사용자 최적화** | 10명 시 65초 → 40초 이내 | KV Cache 최적화 → 성능 개선 | P1 (6월) |
| **B2. 모니터링 시스템** | 응답 시간, 에러율, GPU 사용률 | 추론 로그 → 대시보드 | P1 (6월) |
| **B3. 고가용성 구성** | 장애 복구, 로드밸런싱 | 단일 서버 → HA 구성 | P2 (12월) |

#### C. 백엔드/API 영역

| 항목 | 범위 | 입력 → 출력 | 우선순위 |
|------|------|------------|---------|
| **C1. 프레임워크 분리** | xFrame5 → MCP 기반 분리 | 강결합 코드 → FrameworkAdapter | P0 (6월) |
| **C2. API 고도화** | 배치 처리, 비동기 지원 | 단순 API → 고급 API | P1 (6월) |
| **C3. 멀티 프레임워크** | Spring, Vue, React 지원 | 프레임워크 요청 → 해당 코드 생성 | P2 (12월) |

#### D. 품질/테스트 영역

| 항목 | 범위 | 입력 → 출력 | 우선순위 |
|------|------|------------|---------|
| **D1. 모델 품질 벤치마크** | 자동화 측정 시스템 | 테스트 케이스 → 품질 점수 | P0 (6월) |
| **D2. 부하 테스트 자동화** | RPS, 응답 시간 측정 | 시나리오 → 성능 리포트 | P1 (6월) |
| **D3. E2E 테스트** | 전체 파이프라인 검증 | 생성 요청 → 검증 결과 | P1 (6월) |

### 2.3 API 인터페이스 (Phase 1부터 사용)

| 항목 | 엔드포인트 | Phase 1 담당 |
|------|----------|--------------|
| 코드 생성 | `POST /agent/agentic/v2/stream` | 대보DX (구현) + 시선AI (vLLM 지원) |
| 코드 리뷰 | `POST /agent/review` | 대보DX |
| Q&A | `POST /agent/qa` | 대보DX |
| 모델 목록 | `GET /agent/models` | 시선AI (vLLM 배포) |

---

## 3. 투입 인력 계획

### 3.1 필요 역할 (전체 기간)

| 역할                    | 주요 업무                   | 필요 역량                     |
| --------------------- | ----------------------- | ------------------------- |
| **Tech Lead (서브PO)**  | 프로젝트 관리, 대보DX 협업, 기술 방향 | 프로젝트 관리, 아키텍처             |
| **ML Engineer**       | 모델 파인튜닝, 프롬프트 엔지니어링     | LLM, PyTorch, HuggingFace |
| **MLOps/Infra**       | vLLM 배포, GPU 인프라, 모니터링  | vLLM, CUDA, Docker, K8s   |
| **Backend Developer** | API 개발, 프레임워크 분리        | Rust, REST API, MCP       |
| **QA Engineer**       | 품질 테스트, 벤치마크 자동화        | 테스트 자동화, 성능 테스트           |

### 3.2 기간별 투입 계획

#### Phase 1: 1-3월 (서포트 단계)

> **제약**: 시선AI 실질적 인력 투입 어려움 → 최소 서포트만

| 역할               | 인원     | 투입률         | 주요 업무              |
| ---------------- | ------ | ----------- | ------------------ |
| Tech Lead (서브PO) | 1명     | **20%**     | 대보DX 협업, 기술 자문     |
| MLOps/Infra      | 1명     | **30%**     | GPU 셋업, vLLM 배포 지원 |
| ML Engineer      | 1명     | **10%**     | 모델 선정 자문, 프롬프트 가이드 |
| **합계**           | **3명** | **0.6 FTE** |                    |

**Phase 1 산출물**:
- GPU 환경 구성 완료
- vLLM 추론 엔드포인트 배포
- 모델 선정 (GPT-OSS 20B 권장)
- 대보DX PoC 기술 지원

#### Phase 2: 4-6월 (본격 투입)

> **전환점**: 시선AI 본격 개발 시작

| 역할 | 인원 | 투입률 | 주요 업무 |
|------|------|--------|----------|
| Tech Lead (서브PO) | 1명 | 50% | 아키텍처 설계, 프로젝트 관리 |
| ML Engineer | 1명 | 100% | 모델 품질 개선, 경량 모델 |
| MLOps/Infra | 1명 | 60% | 성능 최적화, 모니터링 |
| Backend Developer | 1명 | 100% | 프레임워크 분리 (MCP) |
| QA Engineer | 1명 | 50% | 벤치마크, 부하 테스트 |
| **합계** | **5명** | **3.6 FTE** | |

#### Phase 3: 7-12월 (상용화)

| 역할 | 인원 | 투입률 | 주요 업무 |
|------|------|--------|----------|
| Tech Lead (서브PO) | 1명 | 30% | 기술 지원, 고객 대응 |
| ML Engineer | 1명 | 80% | 멀티 프레임워크 모델 |
| MLOps/Infra | 1명 | 40% | 인프라 안정화, HA 구성 |
| Backend Developer | 1명 | 80% | 멀티 프레임워크 API |
| QA Engineer | 1명 | 40% | E2E, 회귀 테스트 |
| **합계** | **5명** | **2.7 FTE** | |

### 3.3 인력 투입 요약

| Phase | 기간 | FTE | 핵심 역할 |
|-------|------|-----|----------|
| **Phase 1** | 1-3월 | **0.6** | 서포트 (인프라 + vLLM) |
| **Phase 2** | 4-6월 | **3.6** | 본격 개발 |
| **Phase 3** | 7-12월 | **2.7** | 상용화 |

---

## 4. 상세 로드맵

### 4.1 Phase 1: 1-3월 (PoC 지원)

**목표**: 대보DX PoC 성공 지원 + SoftBase 데모 준비

> **핵심**: 대보DX가 개발 주도, 시선AI는 인프라/vLLM 서포트

#### 대보DX 일정 (문기봉 상무 단독)

| 기간 | 마일스톤 | 산출물 |
|------|----------|--------|
| 1-2월 | Coder 프로토타입 개발 | 기본 동작 프로토타입 |
| 2월 | CLI 명령어 구현 | generate, batch, models |
| 2-3월 | 파일 편집 기능 | 6단계 파이프라인 |
| 3월 말 | SoftBase 데모 | xFrame5 코드 생성 시연 |

#### 시선AI 일정 (서포트)

| 주차 | 마일스톤 | 담당 | 산출물 |
|------|----------|------|--------|
| W1-2 (1/27-2/7) | GPU 인프라 셋업 | MLOps (30%) | 환경 구성 완료 |
| W3-4 (2/10-2/21) | vLLM 배포 | MLOps (30%) | 추론 엔드포인트 |
| W5-6 (2/24-3/7) | 모델 선정 및 테스트 | ML (10%) | GPT-OSS 20B 또는 Qwen32B |
| W7-10 (3/10-3/31) | 기술 자문 | Tech Lead (20%) | 질의응답, 이슈 해결 |

**Phase 1 검증 기준**:
- vLLM 엔드포인트 정상 동작
- 모델 응답: 1명 사용 시 30초 이내 (GPT-OSS 20B 기준 ~15초)
- 대보DX PoC 데모 지원 완료

### 4.2 Phase 2: 4-6월 (본격 개발)

**목표**: 프레임워크 분리 완료, 모델 품질 개선, 성능 최적화

> **전환점**: 시선AI 본격 투입 (3.6 FTE)

| 기간 | 마일스톤 | 담당 | 산출물 |
|------|----------|------|--------|
| 4월 초 | MCP 아키텍처 설계 | Backend + Tech Lead | 설계 문서 |
| 4월 중-5월 초 | FrameworkAdapter 구현 | Backend (100%) | xFrame5 MCP Server |
| 5월 중 | 모델 품질 개선 | ML (100%) | Qwen32B 54% → 80%+ |
| 5월 말-6월 초 | 동시 사용자 최적화 | MLOps (60%) | 10명 40초 이내 |
| 6월 중-말 | 경량 모델 QA 전용 | ML (100%) | 7B QA 모델 (85%+) |

**Phase 2 검증 기준**:
- 프레임워크 분리: xFrame5를 MCP Server로 완전 분리
- 모델 품질: Qwen32B 80%+ (벤치마크 측정)
- 동시 사용자: 10명 시 평균 40초 이내

### 4.3 Phase 3: 7-12월 (상용화)

**목표**: 멀티 프레임워크 지원, 상용 제품 출시

| 기간 | 마일스톤 | 담당 | 산출물 |
|------|----------|------|--------|
| 7-8월 | Spring Adapter | Backend + ML | Spring MCP Server (80%+) |
| 9-10월 | Vue/React Adapter | Backend + ML | 프론트엔드 MCP Server (75%+) |
| 11월 | 통합 테스트 + 안정화 | 전체 | E2E 95%+ 통과 |
| 12월 | 상용 출시 | 전체 | v1.0 + 운영 가이드 |

**Phase 3 검증 기준**:
- Spring 품질: 코드 생성 80%+
- Vue/React 품질: 컴포넌트 생성 75%+
- 운영 안정성: 99% 가용성

---

## 5. 리스크 및 의존성

### 5.1 Phase 1 의존성 (가장 중요)

| 의존성 | 영향 | 완화 방안 | 담당 |
|--------|------|----------|------|
| **GPU 인프라 공유** | vLLM 배포 불가 | 1월 중 협의 완료, 클라우드 백업 | 시선AI MLOps |
| **대보DX 단독 개발** | PoC 일정 지연 가능 | 시선AI 기술 자문 적극 지원 | Tech Lead |
| **모델 선정** | 품질/성능 트레이드오프 | GPT-OSS 20B 권장 (이미 94%) | ML |

### 5.2 기술적 리스크

| 리스크 | 확률 | 영향 | 완화 방안 |
|--------|------|------|----------|
| **Phase 1 인프라 지연** | 20% | 높음 | 2월 중순까지 환경 구성 완료 목표 |
| **대보DX 리소스 부족** | 30% | 높음 | 시선AI 기술 자문 강화, 비동기 지원 |
| **모델 품질 목표 미달 (Phase 2)** | 30% | 중간 | GPT-OSS 20B 백업 옵션 유지 |
| **동시 사용자 성능 미달** | 15% | 중간 | A100 확보, 배치 처리 강화 |

### 5.3 Phase 1 핵심 리스크

> **가장 큰 리스크**: 문기봉 상무 단독으로 3월까지 PoC 완성 가능 여부

**완화 전략**:
1. 시선AI가 인프라/vLLM은 확실히 지원 (MLOps 30%)
2. 기술 질의에 신속 대응 (Tech Lead 20%)
3. 모델은 이미 검증된 GPT-OSS 20B 사용 → 모델 개발 부담 제거

---

## 6. 예산 개요

### 6.1 인력 비용 (예상)

| 기간 | FTE | 월 비용 (예상) | 합계 |
|------|-----|---------------|------|
| 1-3월 | **0.6** | ~500만원 | **1,500만원** |
| 4-6월 | 3.6 | ~2,900만원 | 8,700만원 |
| 7-12월 | 2.7 | ~2,200만원 | 13,200만원 |
| **연간** | - | - | **2.34억원** |

> **기존 대비**: 0.6억원 절감 (3.1 FTE → 0.6 FTE in Phase 1)

### 6.2 인프라 비용

| 항목 | 비용 | 비고 |
|------|------|------|
| GPU (대보DX 공유 시) | 0원 | 인프라 공유 |
| GPU (별도 구매 시) | 2,800만원 | A100 80GB |
| 클라우드 백업 | 월 65-150만원 | GCP a2-1g |

### 6.3 Phase 1 비용 최소화

> Phase 1은 서포트 역할이므로 인력 비용 최소화

| 역할 | 투입률 | 월 비용 (예상) |
|------|--------|---------------|
| Tech Lead | 20% | ~150만원 |
| MLOps | 30% | ~200만원 |
| ML | 10% | ~100만원 |
| **합계** | **0.6 FTE** | **~450만원/월** |

---

## 7. 핵심 성공 요인

### Phase 1 (가장 중요)

1. **GPU 인프라 확보**: 대보DX와 공유 협의 1월 중 완료
2. **vLLM 배포 완료**: 2월 중순까지 추론 엔드포인트 정상 동작
3. **모델 선정**: GPT-OSS 20B 권장 (이미 94% 품질, 모델 개발 불필요)
4. **대보DX 지원**: 기술 질의에 신속 대응

### Phase 2 이후

1. **본격 인력 투입**: 4월부터 3.6 FTE
2. **프레임워크 분리**: MCP 기반 아키텍처로 확장성 확보
3. **모델 품질 개선**: Qwen32B(54%) → 80%+ 달성

---

## 8. 참고 문서

- [[02_implementation/roadmap_ko|기존 로드맵]] - 기능 중심 로드맵
- [[03_development/2026-01-15_project_intro/model_benchmark|모델 벤치마크]] - GPT-OSS 94%, Qwen32B 54%
- [[03_development/2026-01-15_project_intro/load_test_qwen32b|부하 테스트]] - 25-65초
- [[03_development/2026-01-24_progress/architecture_mcp|MCP 아키텍처]] - 프레임워크 분리 설계
- [[02_implementation/cost_analysis_ko|비용 분석]] - 인프라 비용 상세

---

## 9. 검증 방법

### Phase 1 검증

| 항목 | 방법 | 기준 |
|------|------|------|
| vLLM 배포 | 엔드포인트 호출 테스트 | 정상 응답 |
| 모델 응답 시간 | curl로 측정 | 1명 30초 이내 |
| GPU 환경 | nvidia-smi 확인 | 정상 동작 |

### Phase 2 이후 검증

1. **모델 품질**: `03_development/model_benchmark.md` 테스트 케이스로 벤치마크
2. **응답 시간**: `03_development/load_test_qwen32b.md` 방식으로 부하 테스트
3. **CLI 기능**: `03_development/cli_test/cli_test_report.md` 테스트 스크립트 실행
4. **API 동작**: Postman/curl로 각 엔드포인트 테스트

---

## 변경 이력

| 버전 | 일자 | 변경 내용 |
|------|------|----------|
| 1.0 | 2026-01-26 | 초안 작성 |
| **2.0** | **2026-01-26** | **현실 제약 반영**: Phase 1 서포트 역할로 변경, 0.6 FTE |
