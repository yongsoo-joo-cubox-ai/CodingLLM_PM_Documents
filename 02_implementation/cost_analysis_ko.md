# Coco 인프라 비용 분석

| 항목 | 내용 |
|------|------|
| **문서번호** | SAI-IMPL-2026-003 |
| **작성일** | 2026년 1월 21일 |
| **버전** | v1.0 |
| **보안등급** | 대외비 |
| **작성** | Secern AI |

> **구현 문서 3/5** | 이전: [투입 인력](./resource_plan_ko.md) | 다음: [기술 스택](./phase2_tech_stack_ko.md) | [폴더 인덱스](./README.md)

---

## 개요

Coco 온프레미스 배포에 필요한 인프라 비용을 분석합니다. 클라우드 대안과 비교하여 TCO(Total Cost of Ownership)를 산출합니다.

### 비용 요약

| 구분 | 온프레미스 (3년) | 클라우드 (3년) | 권장 |
|------|----------------|---------------|------|
| **초기 비용** | 3,500만-7,000만원 | 0원 | - |
| **운영 비용** | 연 1,200만-2,400만원 | 연 2,500만-5,000만원 | - |
| **3년 TCO** | **7,100만-14,200만원** | **7,500만-15,000만원** | ✅ 온프레미스 |

> **결론**: 상시 운영 시 온프레미스가 비용 효율적. PoC/간헐적 사용 시 클라우드 권장.

---

## 1. 하드웨어 비용 상세

### 1.1 GPU 서버 옵션

| GPU 모델 | VRAM | 가격 (USD) | 가격 (KRW) | Qwen-32B 지원 |
|----------|------|-----------|-----------|---------------|
| NVIDIA RTX 4090 | 24GB | $1,600 | 210만원 | ❌ (메모리 부족) |
| NVIDIA A40 | 48GB | $5,000 | 650만원 | △ (양자화 필요) |
| **NVIDIA A100 80GB** | 80GB | $15,000 | 1,950만원 | ✅ 권장 |
| NVIDIA H100 | 80GB | $30,000 | 3,900만원 | ✅ 최고 성능 |
| NVIDIA L40S | 48GB | $8,000 | 1,040만원 | △ (양자화 필요) |

> **권장**: A100 80GB. 가격 대비 성능 최적. H100은 예산 여유 시 고려.

### 1.2 서버 구성 옵션

#### 옵션 A: 최소 구성 (PoC/소규모)

| 구성요소 | 사양 | 가격 |
|----------|------|------|
| GPU | A40 x1 (48GB) | 650만원 |
| CPU | AMD EPYC 7313 (16C) | 150만원 |
| RAM | 128GB DDR4 ECC | 80만원 |
| Storage | 1TB NVMe SSD | 30만원 |
| 서버 섀시 | 타워형 | 50만원 |
| 네트워크 | 10GbE NIC | 20만원 |
| **소계** | | **980만원** |

#### 옵션 B: 권장 구성 (프로덕션)

| 구성요소 | 사양 | 가격 |
|----------|------|------|
| GPU | A100 80GB x1 | 1,950만원 |
| CPU | AMD EPYC 7543 (32C) | 400만원 |
| RAM | 256GB DDR4 ECC | 160만원 |
| Storage | 2TB NVMe RAID | 80만원 |
| 서버 섀시 | 랙마운트 4U | 100만원 |
| 네트워크 | 25GbE NIC | 50만원 |
| 이중화 PSU | 2000W x2 | 60만원 |
| **소계** | | **2,800만원** |

#### 옵션 C: 고성능 구성 (대규모)

| 구성요소 | 사양 | 가격 |
|----------|------|------|
| GPU | H100 x1 또는 A100 x2 | 3,900만원 |
| CPU | AMD EPYC 9654 (96C) | 800만원 |
| RAM | 512GB DDR5 ECC | 400만원 |
| Storage | 4TB NVMe RAID | 160만원 |
| 서버 섀시 | 랙마운트 8U | 200만원 |
| 네트워크 | 100GbE NIC | 150만원 |
| 이중화 PSU | 3000W x2 | 100만원 |
| **소계** | | **5,710만원** |

### 1.3 추가 인프라 비용

| 항목 | 최소 | 권장 | 비고 |
|------|------|------|------|
| 랙 설치 | 50만원 | 150만원 | 전용 랙 |
| 냉각 시스템 | 100만원 | 300만원 | 추가 쿨링 |
| UPS | 100만원 | 300만원 | 무정전 전원 |
| 네트워크 장비 | 50만원 | 200만원 | 스위치, 방화벽 |
| **소계** | **300만원** | **950만원** | |

---

## 2. 운영 비용 상세

### 2.1 전력 비용

| 구성 | 전력 소비 | 월간 비용 | 연간 비용 |
|------|----------|----------|----------|
| A40 서버 | 700W | 35만원 | 420만원 |
| **A100 서버** | 1,000W | 50만원 | **600만원** |
| H100 서버 | 1,200W | 60만원 | 720만원 |

> 계산 기준: 24시간 운영, 산업용 전기 160원/kWh

### 2.2 냉각 비용

| 구성 | 냉각 부하 | 월간 비용 | 연간 비용 |
|------|----------|----------|----------|
| A40 서버 | 500W | 25만원 | 300만원 |
| **A100 서버** | 700W | 35만원 | **420만원** |
| H100 서버 | 900W | 45만원 | 540만원 |

### 2.3 인력 비용

| 역할 | 투입률 | 월 비용 | 연 비용 |
|------|--------|--------|--------|
| **시스템 관리자** | 30% | 150만원 | 1,800만원 |
| 네트워크 관리 | 10% | 50만원 | 600만원 |
| 보안 관리 | 10% | 50만원 | 600만원 |
| **합계** | 50% | **250만원** | **3,000만원** |

> 기준: 내부 인력 겸직 시. 전담 인력 배치 시 2배 이상 증가.

### 2.4 유지보수 비용

| 항목 | 월 비용 | 연 비용 | 비고 |
|------|--------|--------|------|
| 하드웨어 점검 | 10만원 | 120만원 | 분기별 정기 점검 |
| 소프트웨어 업데이트 | 5만원 | 60만원 | vLLM, CUDA 등 |
| 장애 대응 예비비 | 20만원 | 240만원 | 부품 교체 등 |
| **합계** | **35만원** | **420만원** | |

---

## 3. 클라우드 대안 비교

### 3.1 클라우드 제공자별 비용

| 제공자 | 인스턴스 | GPU | 시간당 비용 | 일 비용 (8시간) |
|--------|----------|-----|-----------|----------------|
| **AWS** | p4d.24xlarge | A100 x8 | $32.77 | $262 |
| **AWS** | p4de.24xlarge | A100 x8 | $40.96 | $328 |
| **GCP** | a2-highgpu-1g | A100 x1 | $3.67 | $29 |
| **GCP** | a2-ultragpu-1g | A100 x2 | $7.35 | $59 |
| **Azure** | NC24ads A100 v4 | A100 x1 | $3.67 | $29 |
| **Azure** | ND96asr A100 v4 | A100 x8 | $27.20 | $218 |

### 3.2 사용 패턴별 월간 비용

| 사용 패턴 | 설명 | AWS (p4de) | GCP (a2-1g) | Azure (NC24) |
|----------|------|-----------|-------------|--------------|
| **간헐적** | 2시간/일 x 20일 | $1,638 | $147 | $147 |
| **표준** | 8시간/일 x 22일 | $7,209 | $647 | $647 |
| **집중** | 12시간/일 x 22일 | $10,813 | $969 | $969 |
| **상시** | 24시간/일 x 30일 | $23,594 | $2,642 | $2,642 |

> GCP/Azure A100 x1이 가장 비용 효율적. 월 65만원~265만원.

### 3.3 온프레미스 vs 클라우드 TCO (3년)

#### 시나리오: 표준 사용 (8시간/일)

| 비용 항목 | 온프레미스 (A100) | 클라우드 (GCP a2-1g) |
|----------|------------------|---------------------|
| 초기 비용 | 3,750만원 | 0원 |
| 연간 운영 | 5,000만원 | 8,500만원 |
| **3년 TCO** | **1.88억원** | **2.55억원** |

#### 시나리오: 상시 운영 (24시간/일)

| 비용 항목 | 온프레미스 (A100) | 클라우드 (GCP a2-1g) |
|----------|------------------|---------------------|
| 초기 비용 | 3,750만원 | 0원 |
| 연간 운영 | 5,000만원 | 31,700만원 |
| **3년 TCO** | **1.88억원** | **9.51억원** |

> **결론**: 표준 사용 이상이면 온프레미스가 경제적. 간헐적 사용 시 클라우드 권장.

---

## 4. 비용 최적화 전략

### 4.1 양자화 (Quantization) 활용

| 양자화 수준 | GPU 요구량 | 품질 영향 | 비용 절감 |
|------------|-----------|----------|----------|
| FP16 (기본) | 64GB | 기준 | - |
| **INT8** | 32GB | -5% | **50%** |
| INT4 (GPTQ) | 16GB | -10% | 75% |

> **권장**: INT8 양자화로 A40 GPU 사용 가능. 품질 저하 미미.

### 4.2 모델 라우팅 최적화

| 작업 유형 | 권장 모델 | GPU 비용 | 라우팅 효과 |
|----------|----------|---------|------------|
| 코드 생성 (복잡) | **GPT-OSS 20B** | 중간 | 최고 품질 (94%) |
| 코드 생성 (일반) | Qwen-32B | 높음 | 차선 품질 (54%) |
| 코드 리뷰 | Qwen-7B | **낮음** | 비용 절감 |
| Q&A | Qwen-7B (또는 4B) | **낮음** | 비용 절감 |
| 자동완성 | Qwen-1.5B | **매우 낮음** | 비용 최소화 |

> 작업별 모델 라우팅으로 평균 40% 비용 절감 가능 (예상).
> **참고**: GPT-OSS 20B가 Qwen-32B보다 품질 우수. 상세: `03_development/model_benchmark.md`

### 4.3 단계별 도입 전략

| 단계 | 기간 | 인프라 | 월 비용 |
|------|------|--------|--------|
| **PoC** | 1-3개월 | 클라우드 (GCP) | 65만원 |
| **파일럿** | 3-6개월 | 클라우드 (확장) | 150만원 |
| **프로덕션** | 6개월+ | 온프레미스 | 400만원 (평균) |

---

## 5. ROI 분석

### 5.1 개발 생산성 향상 효과 (예상)

| 지표 | 현재 | Coco 도입 후 (목표) | 개선율 |
|------|------|---------------------|--------|
| 코드 작성 속도 | 100줄/시간 | 150줄/시간 | +50% |
| 코드 리뷰 시간 | 2시간/PR | 1시간/PR | -50% |
| 버그 발생률 | 10건/1000줄 | 6건/1000줄 | -40% |

> ⚠️ 위 수치는 **목표치**이며, 실제 효과는 파일럿 후 측정 예정

### 5.2 비용 절감 효과 (연간, 예상)

| 항목 | 산출 근거 | 연간 절감액 (예상) |
|------|----------|-------------------|
| 개발 시간 절감 | 개발자 10명 x 20% 생산성 향상 (목표) | 1.2억원 |
| 코드 리뷰 절감 | 리뷰 시간 50% 감소 (목표) | 3,000만원 |
| 버그 수정 비용 | 버그 40% 감소 (목표) | 5,000만원 |
| **합계** | | **2억원/년 (목표)** |

> ⚠️ 실제 ROI는 파일럿 결과에 따라 재산정 필요

### 5.3 ROI 계산

| 항목 | 금액 |
|------|------|
| 3년 총 비용 (온프레미스) | 1.88억원 |
| 3년 총 절감 효과 | 6억원 |
| **3년 순이익** | **4.12억원** |
| **ROI** | **219%** |

---

## 6. 예산 제안

### 6.1 모델 라이선스

| 모델 | 라이선스 | 상업적 사용 | 비용 |
|------|---------|------------|------|
| **GPT-OSS 20B** | Apache 2.0 | ✅ 허용 | 무료 |
| Qwen2.5-Coder-32B | Apache 2.0 | ✅ 허용 | 무료 |
| vLLM (추론 엔진) | Apache 2.0 | ✅ 허용 | 무료 (Enterprise는 유료) |

> **참고**: 모델 자체는 무료이나, 운영에 필요한 GPU 인프라 비용은 별도

### 6.2 응답 시간 SLA (예상)

| 동시 사용자 | 응답 시간 | 적합 용도 |
|------------|----------|----------|
| 1명 | 25초 | 인터랙티브 사용 |
| 2명 | 28초 | 인터랙티브 사용 |
| 5명 | 45초 | 배치 처리 |
| 10명 | 62-65초 | 백그라운드 작업 |

> **측정 조건**: Qwen32B-AWQ, vLLM, 4x RTX 2080 Ti
> **상세**: `03_development/2026-01-15_project_intro/load_test_qwen32b.md`

### 6.3 초기 예산 (1차년도)

| 항목 | 예산 | 비고 |
|------|------|------|
| 하드웨어 (A100 서버) | 2,800만원 | 권장 구성 |
| 추가 인프라 | 500만원 | 랙, 냉각, UPS |
| 설치 및 구성 | 200만원 | 전문 업체 |
| 라이선스 | 300만원 | vLLM Enterprise (선택, 모델은 무료) |
| **1차년도 합계** | **3,800만원** | |

### 6.4 연간 운영 예산

| 항목 | 연간 예산 | 월 평균 |
|------|----------|--------|
| 전력 + 냉각 | 1,000만원 | 83만원 |
| 인력 | 1,800만원 | 150만원 |
| 유지보수 | 420만원 | 35만원 |
| 예비비 | 200만원 | 17만원 |
| **연간 합계** | **3,420만원** | **285만원** |

### 6.5 3개년 예산 계획

| 연도 | 자본 지출 | 운영 비용 | 합계 |
|------|----------|----------|------|
| 1년차 | 3,800만원 | 3,420만원 | 7,220만원 |
| 2년차 | 0원 | 3,420만원 | 3,420만원 |
| 3년차 | 500만원 (업그레이드) | 3,420만원 | 3,920만원 |
| **3년 합계** | **4,300만원** | **1.03억원** | **1.46억원** |

---

## 7. 결론

### 7.1 권장 사항

| 상황 | 권장 옵션 | 이유 |
|------|----------|------|
| **PoC 단계** | 클라우드 (GCP) | 초기 투자 없음, 빠른 시작 |
| **파일럿** | 클라우드 (확장) | 유연한 확장/축소 |
| **프로덕션 (소규모)** | 온프레미스 A40 + INT8 | 비용 효율 |
| **프로덕션 (권장)** | 온프레미스 A100 | 성능 + 비용 균형 |
| **대규모** | 온프레미스 H100 | 최고 성능 |

### 7.2 의사결정 플로우

```
사용 패턴 분석
    │
    ├─ 간헐적 (< 4시간/일) → 클라우드
    │
    ├─ 표준 (4-8시간/일) → 비용 비교 후 결정
    │
    └─ 상시 (> 8시간/일) → 온프레미스
```

---

## Sources

- [NVIDIA GPU Pricing](https://www.nvidia.com/en-us/data-center/)
- [AWS EC2 Pricing](https://aws.amazon.com/ec2/pricing/)
- [GCP Compute Engine Pricing](https://cloud.google.com/compute/pricing)
- [Azure Virtual Machines Pricing](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/)
- [HuggingFace - Qwen2.5-Coder](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)

---

---

## 관련 문서

- [[strategy/executive_summary_ko|경영진 요약]]
- [[implementation/roadmap_ko|로드맵]]
- [[strategy/regulatory_environment_ko|규제 환경]]

## 변경이력

| 버전 | 일자 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2026-01-21 | 초판 작성 | 분석팀 |
